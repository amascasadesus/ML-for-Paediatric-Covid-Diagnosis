{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Project \"Developing predictive models for COVID-19 diagnosis in paediatric patients: \n",
    "#          A case study about the potentials of Machine Learning in Public Health\"\n",
    "#          By Anna Mas-Casades√∫s (https://github.com/amascasadesus)\n",
    "#          July 2020\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "### Import basic modules and dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import grid\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objs as go \n",
    "import plotly.offline as py\n",
    "import plotly.tools as tls\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings('ignore')\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "symp_raw = pd.read_excel('symptoms_paediatric_original.xlsx')\n",
    "symp = pd.read_excel('symptoms_paediatric_original.xlsx')\n",
    "symp_raw_copy = symp.copy() # create checkpoints\n",
    "symp_copy = symp.copy()\n",
    "\n",
    "\n",
    "###  DATA PRE-PROCESSING I\n",
    "\n",
    "# Drop redundant, duplicated, and unuseful variables\n",
    "symp.drop(['underlying','cxrpn','resp1','o21','linfo1','crp1','neutro1','admission1','sex1'], axis=1, inplace=True) \n",
    "\n",
    "# Create a new variable that codes whether the patient has had a known contact with a Covid+ or not\n",
    "symp['covid_contact'] = symp['diagnosis'].str.contains(pat ='covid+')\n",
    "symp['covid_contact'] = np.multiply(symp['covid_contact'], 1) # convert boolean list to integer\n",
    "\n",
    "# Correct `diagnosis` variable misspellings and erase \"contact with covid+\"\" (as info already collected in `covid_contact`)\n",
    "replace_map_diagnosis = {'diagnosis': {'Covid19':'Covid19', 'Fever without focus':'Fever without focus', \n",
    "                                       'Febrile neutropenia':'Febrile neutropenia', 'Common cold':'Common cold',\n",
    "                                       'Bronchopneumonia':'Bronchopneumonia','Acute pyelonephritis':'Acute pyelonephritis',\n",
    "                                       'Sepsis':'Sepsis','Common cold and covid+ contact':'Common cold', 'Flu':'Flu',\n",
    "                                       'Nasal hematoma and OMA':'Nasal hematoma and OMA',\n",
    "                                       'Non-especified vomiting':'Non-especified vomiting',\n",
    "                                       'Laryngotracheonbronchitis':'Laryngotracheonbronchitis', \n",
    "                                       'Diabetic acidosis':'Diabetic acidosis',\n",
    "                                       'respiratory insuficiency, contact COVID+':'Respiratory insufficiency',\n",
    "                                       'Pyoderma gangrenosum':'Pyoderma gangrenosum', \n",
    "                                       'Septic shock (intestinal origin)':'Septic shock (intestinal origin)',\n",
    "                                       'Hepatic transplant':'Hepatic transplant',\n",
    "                                       'Urinary tract infection':'Urinary tract infection','Sacroiliitis':'Sacroiliitis',\n",
    "                                       'Bronchiolitis obliterans':'Bronchiolitis obliterans',\n",
    "                                       'central venous catheter infecciton':'Central venous catheter infection',\n",
    "                                       'Otitis media':'Otitis media','Bronchiolitis and covid+ contact':'Bronchiolitis',\n",
    "                                       'Intestinal hemorrhage':'Intestinal haemorrhage', 'Bronchiolitis':'Bronchiolitis',\n",
    "                                       'Acute respiratory insuficiency':'Acute respiratory insufficiency',\n",
    "                                       'Aspiration neumonitis':'Aspiration pneumonitis','Miocarditis':'Miocarditis'}}\n",
    "symp.replace(replace_map_diagnosis, inplace=True)\n",
    "\n",
    "# Encode the different diagnoses (by order of frequency)\n",
    "symp['diagnosis_coded'] = symp['diagnosis']\n",
    "replace_map_diagnosis_coded = {'diagnosis_coded': {'Covid19':1,'Fever without focus':2,'Febrile neutropenia':3, 'Common cold':4,\n",
    "                                                   'Pneumonia':5,'Bronchopneumonia':6,'Acute pyelonephritis':7,'Sepsis':8,\n",
    "                                                   'Flu':9,'Bronchiolitis':10,'Laryngotracheobronchitis':11,\n",
    "                                                   'Central venous catheter infection':12,'Respiratory insufficiency':13,\n",
    "                                                   'Sacroiliitis':14,'Pyoderma gangrenosum':15,'Hepatic transplant':16,\n",
    "                                                   'Nasal hematoma and OMA':17,'Non-especified vomiting':18,\n",
    "                                                   'Aspiration pneumonitis':19,'Otitis media':20,'Miocarditis':21,\n",
    "                                                   'Diabetic acidosis':22,'Bronchiolitis obliterans':23,\n",
    "                                                   'Intestinal haemorrhage':24,'Acute respiratory insufficiency':25,\n",
    "                                                   'Septic shock (intestinal origin)':26,'Urinary tract infection':27}}\n",
    "symp.replace(replace_map_diagnosis_coded, inplace=True)\n",
    "\n",
    "# Correct `causal_agent`variable misspellings\n",
    "replace_map_causal_agent = {'causal_agent': {'SARS-cov2':'SARS-cov2','Rhinovirus':'Rhinovirus', \n",
    "                                             'Escherichia coli':'Escherichia coli','Influenza A':'Influenza A',\n",
    "                                             'Adenovirus':'Adenovirus','S agalactiae':'S agalactiae',\n",
    "                                             'Influenza B':'Influenza B','E coli':'Escherichia coli',\n",
    "                                             'metapneumovirus':'Metapneumovirus',\n",
    "                                             'Klebsiella pneumoniae':'Klebsiella pneumoniae carbapenemase',\n",
    "                                             'Staphylococcus aureus meticiline resistant':\n",
    "                                             'Methicillin-resistant Staphylococcus aureus',\n",
    "                                             'Pseudomonas aeruginosa':'Pseudomonas aeruginosa'}}\n",
    "symp.replace(replace_map_causal_agent, inplace=True)\n",
    "symp.causal_agent.value_counts()\n",
    "\n",
    "# Encode the different causal agents (by order of frequency)\n",
    "symp['causal_agent_coded'] = symp['causal_agent']\n",
    "replace_map_causal_agent_coded = {'causal_agent_coded': {'SARS-cov2':1, 'Escherichia coli':2,'Influenza A':3,'Rhinovirus':4,\n",
    "                                                         'S agalactiae':5,'Methicillin-resistant Staphylococcus aureus':6,\n",
    "                                                         'Adenovirus':7,'Metapneumovirus':8,'Pseudomonas aeruginosa':9,\n",
    "                                                         'Klebsiella pneumoniae carbapenemase':10,'Influenza B':11}}\n",
    "symp.replace(replace_map_causal_agent_coded, inplace=True)\n",
    "\n",
    "# Calculate diagnosis delay (i.e. time between symptoms onset and diagnosis)\n",
    "symp['symptomsonset'].replace('asymptomatic', np.nan, inplace=True) # replace asymptomatic values for nan\n",
    "symp['symptomsonset'] = pd.to_datetime(symp['symptomsonset']) # convert `symptomsonset`to datetime64\n",
    "diagnosis_delay_td = symp['diagnosisdate'] - symp['symptomsonset'] # td = timedelta\n",
    "import datetime\n",
    "diagnosis_delay = diagnosis_delay_td.dt.days # transform datetime to numeric\n",
    "symp['diagnosis_delay'] = diagnosis_delay # attach the new variable to the dataframe\n",
    "symp.drop(['symptomsonset','diagnosisdate'], axis=1, inplace=True) # remove `symptomsonset` and `diagnosisdate` as we are \n",
    "                                                                        # only interested in `diagnosis_delay`\n",
    "\n",
    "# Replace `admbyother` variable \".\" values for 0 = no\n",
    "symp['admbyother'].replace({'.': 0},inplace=True)\n",
    "\n",
    "# Replace `cxrpneumonia`variable \".\" values for 0 = no\n",
    "symp['cxrpneumonia'].replace({'.': 0},inplace=True)\n",
    "\n",
    "# Correct `virusname` misspellings\n",
    "#replace_map_virusname = {'virusname': {'ND':'no','Rhinovirus':'Rhinovirus','Influenza A':'Influenza A',\n",
    "#                                       'Adenovirus':'Adenovirus','No':'no', 'Adenovirus (a sang)':'Adenovirus',\n",
    "#                                       'Metapneumovirus':'Metapneumovirus'}}\n",
    "#symp.replace(replace_map_virusname, inplace=True)\n",
    "\n",
    "# Create a `other_virus_summary` variable automatically retrieving the presence of viruses from `causal_agent`\n",
    "# Virus = (SARS-cov2), Rhinovirus (1), Influenza A (2), Metapneumovirus (3), Influenza B (4), Adenovirus (5), no (6)\n",
    "symp.drop(['virusname'], axis=1, inplace=True) # erase `virusname`\n",
    "def other_virus(v):\n",
    "    if (v['causal_agent'] == \"Rhinovirus\"):\n",
    "        return 1\n",
    "    elif (v['causal_agent'] == \"Influenza A\"):  \n",
    "        return 2\n",
    "    elif (v['causal_agent'] == \"Metapneumovirus\"):\n",
    "        return 3\n",
    "    elif (v['causal_agent'] == \"Influenza B\"):\n",
    "        return 4\n",
    "    elif (v['causal_agent'] == \"Adenovirus\"):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6               \n",
    "symp['other_virus_summary'] = symp.apply(other_virus, axis=1)\n",
    "\n",
    "# Create a variable with the labels of `other_virus_summary`\n",
    "symp['other_virus_summary_labels'] = symp['other_virus_summary']\n",
    "replace_map_other_virus_summary_labels = {'other_virus_summary_labels': {1:'Rhinovirus',2:'Influenza A',3:'Metapneumovirus',\n",
    "                                                                         4:'Influenza B',5:'Adenovirus',6:'No'}}\n",
    "symp.replace(replace_map_other_virus_summary_labels, inplace=True)\n",
    "\n",
    "# Encode the different categories for `other_virus_summary` into independent yes/no variables via one-hot encoding\n",
    "symp['other_virus_summary_labels2'] = symp['other_virus_summary_labels'] # duplicate `bacteria_summary_labels' \n",
    "symp = pd.get_dummies(symp, columns=['other_virus_summary_labels2'], prefix = ['other_virus']) # apply one-hot enconding\n",
    "symp.drop(['other_virus_No'], axis=1, inplace=True) # remove `other_virus_no` as it is a duplicate of `othervirus` \n",
    "\n",
    "# Create a `bacteria_summary` variable automatically retrieving the presence of bacteria from `causal_agent`\n",
    "# Bacteria = Escherichia coli (1), Klebsiella pneumoniae carbapenemase (2), S agalactiae (3), Pseudomonas aeruginosa (4),\n",
    "    # Methicillin-resistant Staphylococcus aureus (5)\n",
    "def bacteria(v):\n",
    "    if (v['causal_agent'] == \"Escherichia coli\"):\n",
    "        return 1\n",
    "    elif (v['causal_agent'] == \"Klebsiella pneumoniae carbapenemase\"):  \n",
    "        return 2\n",
    "    elif (v['causal_agent'] == \"S agalactiae\"):\n",
    "        return 3\n",
    "    elif (v['causal_agent'] == \"Pseudomonas aeruginosa\"):\n",
    "        return 4\n",
    "    elif (v['causal_agent'] == \"Methicillin-resistant Staphylococcus aureus\"):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6               \n",
    "symp['bacteria_summary'] = symp.apply(bacteria, axis=1)\n",
    "\n",
    "# Create a variable with the labels of `bacteria_summary`\n",
    "symp['bacteria_summary_labels'] = symp['bacteria_summary']\n",
    "replace_map_bacteria_summary_labels = {'bacteria_summary_labels': {1:'Escherichia coli',2:'Klebsiella pneumoniae carbapenemase',\n",
    "                                                                   3:'S agalactiae',4:'Pseudomonas aeruginosa',\n",
    "                                                                   5:'Methicillin-resistant Staphylococcus aureus',6:'No'}}\n",
    "symp.replace(replace_map_bacteria_summary_labels, inplace=True)\n",
    "\n",
    "# Encode the different categories for `bacteria_summary` via one-hot encoding\n",
    "symp['bacteria_summary_labels2'] = symp['bacteria_summary_labels'] # duplicate `bacteria_summary_labels' \n",
    "symp = pd.get_dummies(symp, columns=['bacteria_summary_labels2'], prefix = ['bacteria']) # apply one-hot enconding\n",
    "replace_map_bacteria_no = {'bacteria_No': {0:1,1:0}} # values for `bacteria_no` are reversed; correct them\n",
    "symp.replace(replace_map_bacteria_no, inplace=True)\n",
    "\n",
    "# Replace `ab` variable missing values for 0 = no\n",
    "symp['ab'].fillna(value=0, inplace=True)\n",
    "\n",
    "# Remove `abtype` (26 combinations of unidentified types of antibiotics with no use)\n",
    "symp.drop(['abtype'], axis=1, inplace=True) \n",
    "\n",
    "# Update `age1` (0 <= 1yo, 1 <= 5yo, 2 <= 10yo, 3 > 10yo) with `age` info\n",
    "def age1(v):\n",
    "    if (v['age'] <= 1):\n",
    "        return 0\n",
    "    elif (v['age'] <= 5):  \n",
    "        return 1\n",
    "    elif (v['age'] <= 10):\n",
    "        return 2\n",
    "    elif (v['age'] > 10 ):\n",
    "        return 3\n",
    "symp['age1'] = symp.apply(age1, axis=1)\n",
    "\n",
    "# Update `age2` (0 <= 5yo, 1 > 5yo) with `age`info\n",
    "def age2(v):\n",
    "    if (v['age'] <= 5):\n",
    "        return 0\n",
    "    elif (v['age'] > 5 ):\n",
    "        return 1\n",
    "symp['age2'] = symp.apply(age2, axis=1)\n",
    "\n",
    "# Replace `neutro` variable \"0\" values for nan\n",
    "replace_map_neutro = {'neutro': {0:'.'}}\n",
    "symp.replace(replace_map_neutro, inplace=True)\n",
    "symp['neutro'].replace('.', np.nan, inplace=True)\n",
    "\n",
    "# Replace `linfo` variable \"0\" values for nan\n",
    "replace_map_linfo = {'linfo': {0:'.'}}\n",
    "symp.replace(replace_map_linfo, inplace=True)\n",
    "symp['linfo'].replace('.', np.nan, inplace=True)\n",
    "\n",
    "# Replace `crp` variable \".\" values for nan\n",
    "symp['crp'].replace('.', np.nan, inplace=True)\n",
    "symp['crp'] = symp.crp.astype(float) # convert to float\n",
    "\n",
    "# Change names of variables for ease of use purposes\n",
    "symp.columns = ['id', 'age', 'gender', 'diagnosis_covid', 'diagnosis_summary_labels', 'causal_agent_summary_labels',\n",
    "       'underlying_conditions', 'immunosupressed', 'pid_sid', 'admission', 'admmission_by_covid',\n",
    "       'admission_by_other', 'admission_picu', 'respiratory', 'gastrointestinal', 'fever', 'cxr', 'pneumonia',\n",
    "       'oxigen', 'imv', 'inotropics', 'other_virus', 'antibiotics', 'corticoids', 'death', 'age_group1', \n",
    "       'age_group2', 'neutrocytes', 'lymphocytes', 'crp', 'covid_contact', 'diagnosis_summary', \n",
    "       'causal_agent_summary', 'diagnosis_delay', \n",
    "       'other_virus_summary', 'other_virus_summary_labels', \n",
    "       'other_virus_adv', 'other_virus_iva', \n",
    "       'other_virus_ivb','other_virus_mpv', \n",
    "       'other_virus_rv', 'bacteria_summary', 'bacteria_summary_labels',\n",
    "       'bacteria_ecoli',\n",
    "       'bacteria_kpn',\n",
    "       'bacteria_mrsa', 'bacteria',\n",
    "       'bacteria_paea', 'bacteria_sagl']\n",
    "\n",
    "# Standardise continuous variables\n",
    "symp['age_std'] = symp['age'] # Duplicate the variables to standardise (we want to keep the original values for \n",
    "                                    # interpretation & visualisation purposes)\n",
    "symp['neutrocytes_std'] = symp['neutrocytes']\n",
    "symp['lymphocytes_std'] = symp['lymphocytes']\n",
    "symp['crp_std'] = symp['crp'] \n",
    "symp['diagnosis_delay_std'] = symp['diagnosis_delay'] \n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "variables_to_standardise = ['age_std','neutrocytes_std','lymphocytes_std','crp_std','diagnosis_delay_std'] \n",
    "scaler = StandardScaler()\n",
    "symp[variables_to_standardise] = scaler.fit_transform(symp[variables_to_standardise])\n",
    "\n",
    "# Fill missing values with MICE method\n",
    "nan = ['neutrocytes_std','lymphocytes_std','crp_std','diagnosis_delay_std'] # Select variables with nan\n",
    "symp_nan = symp[nan]\n",
    "from impyute.imputation.cs import mice\n",
    "nan_mice = mice(symp_nan.values) # apply MICE\n",
    "nan_mice.columns = ['neutrocytes_mice_std','lymphocytes_mice_std','crp_mice_std','diagnosis_delay_mice_std'] # rename \n",
    "nan_nonstd = ['neutrocytes','lymphocytes','crp','diagnosis_delay'] # repeat same process for variables without rescaling\n",
    "                                                                        # for interpreation & visualisation purposes\n",
    "symp_nan_nonstd = symp[nan_nonstd]\n",
    "nan_nonstd_mice = mice(symp_nan_nonstd.values) \n",
    "nan_nonstd_mice = pd.DataFrame(data=nan_nonstd_mice[:,:])\n",
    "nan_nonstd_mice.columns = ['neutrocytes_mice','lymphocytes_mice','crp_mice','diagnosis_delay_mice']\n",
    "symp = pd.concat([symp, nan_mice, nan_nonstd_mice], axis=1, sort=False) # mrge the different variables with the main dataset\n",
    "\n",
    "\n",
    "### DATA PRE-PROCESSING II\n",
    "\n",
    "# Feature selection I: Remove variables with unuseful, unformative, and duplicated info \n",
    "    # and those in conflict with our target (e.g. 'admission_by_covid')\n",
    "sel_variables = ['gender', 'diagnosis_covid', # select the variables to keep\n",
    "       'underlying_conditions',\n",
    "       'immunosupressed', 'pid_sid', 'admission_picu', 'respiratory',\n",
    "       'gastrointestinal', 'fever', 'cxr', 'pneumonia', 'oxigen', 'imv',\n",
    "       'inotropics', 'admission', 'other_virus','antibiotics','bacteria',\n",
    "       'corticoids', 'death', \n",
    "       'covid_contact', \n",
    "       'other_virus_adv', 'other_virus_iva',\n",
    "       'other_virus_ivb', 'other_virus_mpv', 'other_virus_rv',\n",
    "       'bacteria_ecoli',\n",
    "       'bacteria_kpn', 'bacteria_mrsa', 'bacteria_paea',\n",
    "       'bacteria_sagl', 'age_std',\n",
    "       'neutrocytes_mice_std', 'lymphocytes_mice_std', 'crp_mice_std',\n",
    "       'diagnosis_delay_mice_std']                                                     \n",
    "symp_sel = symp[sel_variables]\n",
    "\n",
    "# Feature selection II: Remove variables with less than 20% of the cases for one of the classes\n",
    "sel_variables = ['gender', 'diagnosis_covid', # select variables to keep\n",
    "       'underlying_conditions',\n",
    "       'immunosupressed', 'pid_sid', 'admission_picu', 'respiratory',\n",
    "       'gastrointestinal', 'fever', 'cxr', 'pneumonia', 'oxigen', \n",
    "       'antibiotics', 'corticoids', 'age_std',\n",
    "       'neutrocytes_mice_std', 'lymphocytes_mice_std', 'crp_mice_std',\n",
    "       'diagnosis_delay_mice_std']                                                     \n",
    "symp_sel = symp[sel_variables]\n",
    "\n",
    "# Create another dataset with the select variables with the non-standardised data for interpretation & visualisation purposes\n",
    "sel_variables_ns = ['gender', 'diagnosis_covid', \n",
    "       'underlying_conditions',\n",
    "       'immunosupressed', 'pid_sid', 'admission_picu', 'respiratory',\n",
    "       'gastrointestinal', 'fever', 'cxr', 'pneumonia', 'oxigen', \n",
    "       'antibiotics', 'corticoids', 'age',\n",
    "       'neutrocytes_mice', 'lymphocytes_mice', 'crp_mice',\n",
    "       'diagnosis_delay_mice']                                                     \n",
    "symp_sel_ns = symp[sel_variables_ns]\n",
    "\n",
    "# Define X and y and do the Train/Test split\n",
    "def ttsplit(df,target):\n",
    "    \"\"\"\n",
    "    Splits X and y into train and test subsets\n",
    "    df = dataframe\n",
    "    target = target variable\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = df.drop([target],axis=1), df[target] \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,stratify=df[target])\n",
    "                                                     # random_state=42 because we want the same splitting each time run it\n",
    "                                                     # stratified split = keeps the same proportions of class target for\n",
    "                                                         # train and test subsets (since target is imbalanced)\n",
    "    return X_train, X_test, y_train, y_test, X, y\n",
    "Xsel_train, Xsel_test, ysel_train, ysel_test, Xsel, ysel = ttsplit(symp_sel,'diagnosis_covid') # standardised data\n",
    "Xselns_train, Xselns_test, yselns_train, yselns_test, Xselns, yselns = ttsplit(symp_sel_ns,'diagnosis_covid') # non-standardised\n",
    "\n",
    "# Oversample the minority class with the SMOTE-NC method: Train (standardised data)\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from collections import Counter\n",
    "sm = SMOTENC(random_state=42, \n",
    "             categorical_features=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "Xsel_trainres, ysel_trainres = sm.fit_resample(Xsel_train,ysel_train)\n",
    "print('Original dataset (y_train) samples per class {}'.format(Counter(ysel_train)))\n",
    "print('Resampled dataset (y_trainres) samples per class {}'.format(Counter(ysel_trainres)))\n",
    "\n",
    "# Oversample the minority class with the SMOTE-NC method: Train (non-standardised data)\n",
    "sm = SMOTENC(random_state=42, \n",
    "             categorical_features=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "Xselns_trainres, yselns_trainres = sm.fit_resample(Xselns_train,yselns_train)\n",
    "print('Original dataset (y_train) samples per class {}'.format(Counter(yselns_train)))\n",
    "print('Resampled dataset (y_trainres) samples per class {}'.format(Counter(yselns_trainres)))\n",
    "Xselns_trainres.tail(10)\n",
    "\n",
    "# Oversample the minority class with the SMOTE-NC method: Test (standardised data)\n",
    "sm = SMOTENC(random_state=42, \n",
    "             categorical_features=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "Xsel_testres, ysel_testres = sm.fit_resample(Xsel_test,ysel_test)\n",
    "print('Original dataset (y_test) samples per class {}'.format(Counter(ysel_test)))\n",
    "print('Resampled dataset (y_testres) samples per class {}'.format(Counter(ysel_testres)))\n",
    "\n",
    "# Oversample the minority class with the SMOTE-NC method: Test (non-standardised data)\n",
    "sm = SMOTENC(random_state=42, \n",
    "             categorical_features=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "Xselns_testres, yselns_testres = sm.fit_resample(Xselns_test,yselns_test)\n",
    "print('Original dataset (y_test) samples per class {}'.format(Counter(yselns_test)))\n",
    "print('Resampled dataset (y_testres) samples per class {}'.format(Counter(yselns_testres)))\n",
    "\n",
    "\n",
    "### EXPLORATORY DATA ANALYSES\n",
    "\n",
    "# Analysis of variables with respect to frequency and Covid status: Raw dataset\n",
    "symp_raw_copy2 = symp_raw.copy()\n",
    "symp_raw_copy2.drop(['covi19'], axis=1, inplace=True) # drop target variable\n",
    "var = symp_raw_copy2.columns # get features names\n",
    "var = list(var)\n",
    "freqVar = symp_raw.shape[0] - symp_raw[var].isnull().sum() # create Covid+/- frequencies\n",
    "covPos = (symp_raw[symp_raw['covi19']==1].shape[0]\n",
    "         -symp_raw[symp_raw['covi19']==1][var].isnull().sum())/(symp_raw.shape[0] - symp_raw[var].isnull().sum())\n",
    "covNeg = (symp_raw[symp_raw['covi19']==0].shape[0]\n",
    "         -symp_raw[symp_raw['covi19']==0][var].isnull().sum())/(symp_raw.shape[0] - symp_raw[var].isnull().sum())\n",
    "fig, axs = plt.subplots(2, 1, figsize=(25,8))\n",
    "fig.patch.set_facecolor('white')\n",
    "pFreqVar = axs[0].bar(var, freqVar, color='grey', )  # frequency plot\n",
    "axs[0].set_title(\"(a) Frequency of variables available\")\n",
    "axs[0].get_xaxis().set_ticks([])\n",
    "pCovPos = axs[1].bar(var, covPos, color='#1e90ff') # percentage of Covid cases over total tests performed\n",
    "pCovNeg = axs[1].bar(var, covNeg, bottom=covPos, color='#ff8c00')\n",
    "plt.xticks(var, var, rotation='vertical')\n",
    "axs[1].set_title(\"(b) Percentage of Covid cases over total variables available\")\n",
    "axs[1].legend([\"CovidPos\", \"CovidNeg\"])\n",
    "plt.xticks(var, var, rotation='vertical')\n",
    "plt.subplots_adjust(hspace=0.2) \n",
    "fig.suptitle(\"Analysis of variables with respect to frequency and Covid status - Raw dataset\")\n",
    "plt.plot()\n",
    "\n",
    "# Analysis of variables with respect to frequency and Covid status: Pre-processed dataset I\n",
    "symp_copy2 = symp.copy()\n",
    "symp_copy2.drop(['diagnosis_covid'], axis=1, inplace=True) \n",
    "var = symp_copy2.columns\n",
    "var = list(var)\n",
    "freqVar = symp.shape[0] - symp[var].isnull().sum()\n",
    "covPos = (symp[symp['diagnosis_covid']==1].shape[0]\n",
    "         -symp[symp['diagnosis_covid']==1][var].isnull().sum())/(symp.shape[0] - symp[var].isnull().sum())\n",
    "covNeg = (symp[symp['diagnosis_covid']==0].shape[0]\n",
    "         -symp[symp['diagnosis_covid']==0][var].isnull().sum())/(symp.shape[0] - symp[var].isnull().sum())\n",
    "fig, axs = plt.subplots(2, 1, figsize=(25,8))\n",
    "fig.patch.set_facecolor('white')\n",
    "pFreqVar = axs[0].bar(var, freqVar, color='grey', )  \n",
    "axs[0].set_title(\"(a) Frequency of variables available\")\n",
    "axs[0].get_xaxis().set_ticks([])\n",
    "pCovPos = axs[1].bar(var, covPos, color='#1e90ff')\n",
    "pCovNeg = axs[1].bar(var, covNeg, bottom=covPos, color='#ff8c00')\n",
    "plt.xticks(var, var, rotation='vertical')\n",
    "axs[1].set_title(\"(b) Percentage of Covid cases over total variables available\")\n",
    "axs[1].legend([\"CovidPos\", \"CovidNeg\"])\n",
    "plt.xticks(var, var, rotation='vertical')\n",
    "plt.subplots_adjust(hspace=0.2) \n",
    "fig.suptitle(\"Analysis of variables with respect to frequency and Covid status - Pre-processed I dataset\")\n",
    "plt.plot()\n",
    "\n",
    "# Analysis of variables with respect to frequency and Covid status: Pre-processed dataset II\n",
    "symp_sel_copy2 = symp_sel.copy()\n",
    "symp_sel_copy2.drop(['diagnosis_covid'], axis=1, inplace=True) \n",
    "var = symp_sel_copy2.columns\n",
    "var = list(var)\n",
    "freqVar = symp_sel.shape[0] - symp_sel[var].isnull().sum()\n",
    "covPos = (symp_sel[symp_sel['diagnosis_covid']==1].shape[0]\n",
    "         -symp_sel[symp_sel['diagnosis_covid']==1][var].isnull().sum())/(symp_sel.shape[0] - symp_sel[var].isnull().sum())\n",
    "covNeg = (symp_sel[symp_sel['diagnosis_covid']==0].shape[0]\n",
    "         -symp_sel[symp_sel['diagnosis_covid']==0][var].isnull().sum())/(symp_sel.shape[0] - symp_sel[var].isnull().sum())\n",
    "fig, axs = plt.subplots(2, 1, figsize=(25,8))\n",
    "fig.patch.set_facecolor('white')\n",
    "pFreqVar = axs[0].bar(var, freqVar, color='grey', )  \n",
    "axs[0].set_title(\"(a) Frequency of variables available\")\n",
    "axs[0].get_xaxis().set_ticks([])\n",
    "pCovPos = axs[1].bar(var, covPos, color='#1e90ff')\n",
    "pCovNeg = axs[1].bar(var, covNeg, bottom=covPos, color='#ff8c00')\n",
    "plt.xticks(var, var, rotation='vertical')\n",
    "axs[1].set_title(\"(b) Percentage of Covid cases over total variables available\")\n",
    "axs[1].legend([\"CovidPos\", \"CovidNeg\"])\n",
    "plt.xticks(var, var, rotation='vertical')\n",
    "plt.subplots_adjust(hspace=0.2) \n",
    "fig.suptitle(\"Analysis of variables with respect to frequency and Covid status\")\n",
    "plt.plot()\n",
    "\n",
    "# Categorical variables plot\n",
    "symp_sel_copy3 = symp_sel.copy()\n",
    "symp_sel_copy3.drop(['diagnosis_covid','age_std','neutrocytes_mice_std','lymphocytes_mice_std', # drop numerical variables\n",
    "                    'crp_mice_std','diagnosis_delay_mice_std'], axis=1, inplace=True) \n",
    "cat_var = symp_sel_copy3.columns # get features names\n",
    "cat_var = list(cat_var)\n",
    "cat_var[0] = \"male\" # rename `gender`\n",
    "symp_sel.columns = ['male', 'diagnosis_covid', 'underlying_conditions', 'immunosupressed',\n",
    "       'pid_sid', 'admission_picu', 'respiratory', 'gastrointestinal', 'fever',\n",
    "       'cxr', 'pneumonia', 'oxigen', 'antibiotics', 'corticoids', 'age_std',\n",
    "       'neutrocytes_mice_std', 'lymphocytes_mice_std', 'crp_mice_std',\n",
    "       'diagnosis_delay_mice_std']\n",
    "labels = [\"CovidNeg\", \"CovidPos\"] # plot \n",
    "newPal = [\"#ff8c00\", \"#1e90ff\"]\n",
    "fig, axes = plt.subplots(nrows=7, ncols=2, figsize=(15,30))\n",
    "r = 0 # Index row\n",
    "c = 0 # Index col\n",
    "cat_var \n",
    "for f in cat_var:\n",
    "    # Count plot\n",
    "    sns.countplot(x=f, hue='diagnosis_covid', data=symp_sel,ax=axes[r][c], palette=newPal)\n",
    "    # Plot configuration\n",
    "    axes[r][c].legend(labels, loc='upper right')\n",
    "    axes[r][c].set_xticklabels([\"No\", \"Yes\"])\n",
    "    # Index control\n",
    "    c += 1\n",
    "    if c > 1:\n",
    "        c = 0\n",
    "        r += 1\n",
    "\n",
    "# Numerical variables plot\n",
    "symp_sel_copy4 = symp_sel.copy()\n",
    "symp_sel_copy4.drop(['male', 'diagnosis_covid', 'underlying_conditions', 'immunosupressed', # drop categorical variables\n",
    "                     'pid_sid', 'admission_picu', 'respiratory', 'gastrointestinal', 'fever',\n",
    "                     'cxr', 'pneumonia', 'oxigen', 'antibiotics', 'corticoids'], axis=1, inplace=True) \n",
    "num_var = symp_sel_copy4.columns # get features names\n",
    "num_var = list(num_var)\n",
    "labels = [\"CovidNeg\", \"CovidPos\"] # plot\n",
    "newPal = [\"#ff8c00\", \"#1e90ff\"]\n",
    "sns.set(style=\"white\", palette=newPal, color_codes=False)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15,15))\n",
    "r = 0 # Index row\n",
    "c = 0 # Index col\n",
    "for f in num_var:\n",
    "    # Distribution plot\n",
    "    sns.distplot(symp_sel[symp_sel['diagnosis_covid'] == 0][f],label=\"CovidNeg\",ax=axes[r][c])\n",
    "    sns.distplot(symp_sel[symp_sel['diagnosis_covid'] == 1][f],label=\"CovidPos\",ax=axes[r][c])\n",
    "    # Plot configurations\n",
    "    axes[r][c].legend(labels, loc='upper right')\n",
    "    # Index control\n",
    "    c += 1\n",
    "    if c > 1:\n",
    "        c = 0\n",
    "        r += 1\n",
    "        \n",
    "\n",
    "### DATA MODELLING I: PIPELINES\n",
    "\n",
    "# All models pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib\n",
    "import time\n",
    "import xgboost as xgb\n",
    "start = time.time()\n",
    "# Define the combinations of xy variables (i.e. subsets)\n",
    "xy_sel = [Xsel_trainres, Xsel_test, ysel_trainres, ysel_test]\n",
    "xy_selor = [Xsel_train, Xsel_test, ysel_train, ysel_test]\n",
    "xy_list = [xy_sel, xy_selor]\n",
    "xy_liststr = [\"xy_sel\", \"xy_selor\"]\n",
    "# Built pipelines\n",
    "pipe_lr = Pipeline([('clf', LogisticRegression())])\n",
    "pipe_knn = Pipeline([('clf', KNeighborsClassifier())])\n",
    "pipe_svm = Pipeline([('clf', svm.SVC())])\n",
    "pipe_dt = Pipeline([('clf', DecisionTreeClassifier())])\n",
    "pipe_rf = Pipeline([('clf', RandomForestClassifier())])\n",
    "pipe_xgb = Pipeline([('clf', xgb.XGBClassifier())])\n",
    "# Set grid search parameters\n",
    "param_range_1 = [int(x) for x in np.linspace(0.001, 10, num=100)] # cost\n",
    "param_range_2 = [int(x) for x in np.linspace(2, 10, num=9)] # n_neigghbors, max_dexpth, min_samples_leaf \n",
    "param_range_3 = [int(x) for x in np.linspace(2, 20, num=19)] # min_samples_split\n",
    "param_range_4 = [int(x) for x in np.linspace(0, 1, num=20)] # learning_rate\n",
    "param_range_5 = [int(x) for x in np.linspace(0.2, 0.8, num=6)] # colsample_bytree\n",
    "param_range_6 = [int(x) for x in np.linspace(0, 5, num=10)] # min_child_weight\n",
    "param_range_7 = [int(x) for x in np.linspace(0, 0.1, num=5)] # gamma\n",
    "param_range_8 = [int(x) for x in np.linspace(3, 10, num=8)] # n_estimators\n",
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "                   'clf__C': param_range_1,\n",
    "                   'clf__solver': ['liblinear', 'saga', 'lbfgs']}] \n",
    "grid_params_knn = [{'clf__n_neighbors': param_range_2}]\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'],\n",
    "                    'clf__gamma': ['auto','scale'],\n",
    "                    'clf__C': param_range_1}]\n",
    "grid_params_dt = [{'clf__criterion': ['gini', 'entropy'],\n",
    "                   'clf__splitter': ['best','random'],\n",
    "                   'clf__min_samples_leaf': param_range_2,\n",
    "                   'clf__max_depth': param_range_2, \n",
    "                   'clf__min_samples_split': param_range_3}]\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],              \n",
    "                   'clf__min_samples_leaf': param_range_2, \n",
    "                   'clf__max_depth': param_range_2, \n",
    "                   'clf__min_samples_split': param_range_3}]            \n",
    "grid_params_xgb = [{'clf__objective': ['reg:logistic'],\n",
    "                    'clf__subsample': [0.5],\n",
    "                    'clf__max_depth': param_range_2,\n",
    "                    'clf__learning_rate': param_range_4,\n",
    "                    'clf__colsample_bytree': param_range_5,\n",
    "                    'clf__min_child_weight': param_range_5,\n",
    "                    'clf__gamma': param_range_7,\n",
    "                    'clf__n_estimators': param_range_8}] \n",
    "# Built grid searches\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
    "gs_lr = RandomizedSearchCV(estimator=pipe_lr,\n",
    "                     param_distributions=grid_params_lr,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold) \n",
    "gs_knn = RandomizedSearchCV(estimator=pipe_knn,\n",
    "                     param_distributions=grid_params_knn,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold)\n",
    "gs_svm = RandomizedSearchCV(estimator=pipe_svm,\n",
    "                      param_distributions=grid_params_svm,\n",
    "                      scoring='f1_micro',\n",
    "                      cv=kfold)\n",
    "gs_dt = RandomizedSearchCV(estimator=pipe_dt,\n",
    "                     param_distributions=grid_params_dt,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold) \n",
    "gs_rf = RandomizedSearchCV(estimator=pipe_rf,\n",
    "                     param_distributions=grid_params_rf,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold) \n",
    "gs_xgb = RandomizedSearchCV(estimator=pipe_xgb,\n",
    "                     param_distributions=grid_params_xgb,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold) \n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_knn, gs_svm, gs_dt, gs_rf, gs_xgb]\n",
    "# Dictionary of pipelines and classifiers for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression', \n",
    "             1: 'k-Nearest Neighbors', \n",
    "             2: 'Support Vector Machine', \n",
    "             3: 'Decision Tree', \n",
    "             4: 'Random Forest',\n",
    "             5: 'eXtra Gradient Boosting'}\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimisations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "def getxsys(xy):  \n",
    "    \"\"\"\n",
    "    Gets X_train, X_test, y_test, and y_test of each specific subset\n",
    "    \"\"\"\n",
    "    X_train = xy[0]\n",
    "    X_test = xy[1]\n",
    "    y_train = xy[2]\n",
    "    y_test = xy[3]\n",
    "    return X_train, X_test, y_train, y_test # Outside the for loop to optimise processing\n",
    "rounds_list = [\"1st\", \"2nd\" , \"3rd\", \"4th\", \"5th\"]\n",
    "rounds_list_iter = iter(rounds_list)  # Iterates over rounds_list\n",
    "for _ in range(0,5):\n",
    "    round_num = next(rounds_list_iter) # Takes one round item per iteration in rounds_list_iter, sequentially \n",
    "    print('\\nRound:', round_num)\n",
    "    xy_liststr_iter = iter(xy_liststr) # Iteraves over xy_liststr\n",
    "    for xy in xy_list:\n",
    "        X_train, X_test, y_train, y_test = getxsys(xy)\n",
    "        xy_str = next(xy_liststr_iter) # Takes one list name per iteration in xy_liststr_iter, sequentially \n",
    "        print('\\n', xy_str)\n",
    "        for idx, gs in enumerate(grids):\n",
    "            print('\\nEstimator: %s' % (grid_dict[idx]), xy_str)\n",
    "            # Fit grid search\n",
    "            gs.fit(X_train, y_train)\n",
    "            # Best params\n",
    "            print('Best params: %s' % gs.best_params_)\n",
    "            # Best training data accuracy\n",
    "            print('Best training F1 score: %.3f' % gs.best_score_)\n",
    "            # Predict on test data with best params\n",
    "            y_pred = gs.predict(X_test)\n",
    "            # Test data accuracy of model with best params\n",
    "            print('Test set F1 score for best params: %.3f ' % f1_score(y_test, y_pred, average='micro'))\n",
    "            # Track best (highest test accuracy) model\n",
    "            if accuracy_score(y_test, y_pred) > best_acc:\n",
    "                best_acc = accuracy_score(y_test, y_pred)\n",
    "                best_gs = gs\n",
    "                best_clf = idx\n",
    "                best_xy = xy_str\n",
    "    print('\\nClassifier with best test set F1 score: %s' % grid_dict[best_clf], best_xy)\n",
    "end = time.time()\n",
    "print('\\nTotal execution time:', ((end - start)/60), 'min')\n",
    "\n",
    "# Reduced models pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "start = time.time()\n",
    "# Define the combinations of xy variables (i.e. subsets)\n",
    "xy_sel = [Xsel_trainres, Xsel_test, ysel_trainres, ysel_test]\n",
    "xy_selor = [Xsel_train, Xsel_test, ysel_train, ysel_test]\n",
    "xy_list = [xy_sel, xy_selor]\n",
    "xy_liststr = [\"xy_sel\", \"xy_selor\"]\n",
    "# Built pipelines\n",
    "pipe_dummy = Pipeline([('clf', DummyClassifier(random_state=42))])\n",
    "pipe_rf = Pipeline([('clf', RandomForestClassifier(random_state=42))])\n",
    "# Set grid search parameters\n",
    "param_range_2 = [int(x) for x in np.linspace(2, 10, num=9)] # n_neigghbors, max_dexpth, min_samples_leaf \n",
    "param_range_3 = [int(x) for x in np.linspace(2, 20, num=19)] # min_samples_split\n",
    "grid_params_dummy = [{'clf__strategy': ['most_frequent']}]\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],              \n",
    "                   'clf__min_samples_leaf': param_range_2, \n",
    "                   'clf__max_depth': param_range_2, \n",
    "                   'clf__min_samples_split': param_range_3}]            \n",
    "# Built grid searches\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42)\n",
    "gs_dummy = GridSearchCV(estimator=pipe_dummy,\n",
    "                     param_grid=grid_params_dummy,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold) \n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "                     param_grid=grid_params_rf,\n",
    "                     scoring='f1_micro',\n",
    "                     cv=kfold) \n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_dummy, gs_rf]\n",
    "# Dictionary of pipelines and classifiers for ease of reference\n",
    "grid_dict = {0: 'Performance baseline', \n",
    "             1: 'Random Forest'}\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimisations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "def getxsys(xy):  \n",
    "    \"\"\"\n",
    "    Gets X_train, X_test, y_test, and y_test of each specific subset\n",
    "    \"\"\"\n",
    "    X_train = xy[0]\n",
    "    X_test = xy[1]\n",
    "    y_train = xy[2]\n",
    "    y_test = xy[3]\n",
    "    return X_train, X_test, y_train, y_test # Outside the for loop to optimise processing\n",
    "xy_liststr_iter = iter(xy_liststr) # Iterates over xy_liststr\n",
    "for xy in xy_list:\n",
    "    X_train, X_test, y_train, y_test = getxsys(xy)\n",
    "    xy_str = next(xy_liststr_iter) # Takes one list name per iteration in xy_liststr_iter, sequentially\n",
    "    print('\\n', xy_str)\n",
    "    for idx, gs in enumerate(grids):\n",
    "        print('\\nEstimator: %s' % (grid_dict[idx]), xy_str)\n",
    "        # Fit grid search\n",
    "        gs.fit(X_train, y_train)\n",
    "        # Best params\n",
    "        print('Best params: %s' % gs.best_params_)\n",
    "        # Best training data accuracy\n",
    "        print('Best training F1 score: %.3f' % gs.best_score_)\n",
    "        # Predict on test data with best params\n",
    "        y_pred = gs.predict(X_test)\n",
    "        # Test data accuracy of model with best params\n",
    "        print('Test set F1 score for best params: %.3f ' % f1_score(y_test, y_pred, average='micro'))\n",
    "        # Track best (highest test accuracy) model\n",
    "        if accuracy_score(y_test, y_pred) > best_acc:\n",
    "            best_acc = accuracy_score(y_test, y_pred)\n",
    "            best_gs = gs\n",
    "            best_clf = idx\n",
    "            best_xy = xy_str\n",
    "print('\\nClassifier with best test set F1 score: %s' % grid_dict[best_clf], best_xy)\n",
    "end = time.time()\n",
    "print('\\nTotal models executed: 6156')\n",
    "print('\\nTotal execution time:', ((end - start)/60), 'min')\n",
    "\n",
    "\n",
    "### DATA MODELLING II: GLOBAL SURROGATE & EVALUATION\n",
    "\n",
    "# Global Surrogate Method\n",
    "# Random Forest (RF) models definition\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel_ov = RandomForestClassifier(criterion='gini', # Oversampled data - Oversampled model parameters ¬∑ OVERSAMPLED model (OV)\n",
    "                                    max_depth=2,\n",
    "                                    min_samples_leaf=2,\n",
    "                                    min_samples_split=2,\n",
    "                                    random_state=42)\n",
    "rfmodel_ov.fit(Xsel_trainres, ysel_trainres)\n",
    "rfmodel_or = RandomForestClassifier(criterion='entropy', # Original data - Original model parameters ¬∑ ORIGINAL model (OR)\n",
    "                                    max_depth=3,\n",
    "                                    min_samples_leaf=3,\n",
    "                                    min_samples_split=8,\n",
    "                                    random_state=42)\n",
    "rfmodel_or.fit(Xsel_train, ysel_train)\n",
    "# RF predictions\n",
    "yselrf_trainres = rfmodel_ov.predict(Xsel_trainres) # OV\n",
    "yselrf_train = rfmodel_or.predict(Xsel_train) # OR\n",
    "# Decision Tree (DT) models definition\n",
    "from sklearn.tree import DecisionTreeClassifier # OV\n",
    "dtmodel_ov = DecisionTreeClassifier(random_state=42)\n",
    "dtmodel_ov.fit(Xsel_trainres, yselrf_trainres)\n",
    "dtmodel_or = DecisionTreeClassifier(random_state=42) # OR\n",
    "dtmodel_or.fit(Xsel_train, yselrf_train)\n",
    "dtmodelns_ov = DecisionTreeClassifier(random_state=42) # OV with non-standardised data (interpreation & visualisation)\n",
    "dtmodelns_ov.fit(Xselns_trainres, yselrf_trainres)\n",
    "dtmodelns_or = DecisionTreeClassifier(random_state=42) # OR with non-standardised data\n",
    "dtmodelns_or.fit(Xselns_train, yselrf_train)\n",
    "\n",
    "# Performance metrics\n",
    "def performance_metrics(model, X_train, y_train, X_test, y_test, train=True, cv=True):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model\n",
    "    train = True to evaluate train subset, = False test subset\n",
    "    cv = True performs stratified cross-validation\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score \n",
    "    from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "    from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold\n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'prec_micro': 'precision_micro',\n",
    "               'rec_micro': 'recall_micro',\n",
    "               'f1_micro': 'f1_micro',\n",
    "               'auc':'roc_auc'}    \n",
    "    if train==True:\n",
    "        if cv==True:\n",
    "            kfold=StratifiedKFold(n_splits=10, random_state=42)\n",
    "            scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=kfold)\n",
    "            ypredTrain = model.predict(X_train)\n",
    "            Acc_train = scores['test_acc'].mean()\n",
    "            Precision_train = scores['test_prec_micro'].mean()\n",
    "            Recall_train = scores['test_rec_micro'].mean()\n",
    "            F1_train = scores['test_f1_micro'].mean()\n",
    "            AUC_train = scores['test_auc'].mean()\n",
    "            conf_matrix_train = confusion_matrix(y_train, ypredTrain)\n",
    "            class_report = classification_report(y_train, ypredTrain)\n",
    "            print(\"TRAIN:\\n===========================================\")\n",
    "            print(f\"CV - Accuracy : {Acc_train:.2f}\\n\")\n",
    "            print(f\"CV - Precision: {Precision_train:.2f}\\n\")\n",
    "            print(f\"CV - Recall: {Recall_train:.2f}\\n\")\n",
    "            print(f\"CV - F1 score: {F1_train:.2f}\\n\")   \n",
    "            print(f\"CV - AUC score: {AUC_train:.2f}\\n\") \n",
    "            print(f\"Confusion Matrix:\\n {conf_matrix_train}\\n\")\n",
    "            print(f\"Classification Report:\\n {class_report}\\n\")           \n",
    "        elif cv==False:\n",
    "            scores = cross_validate(model, X_train, y_train, scoring=scoring)\n",
    "            ypredTrain = model.predict(X_train)\n",
    "            Acc_train = scores['test_acc'].mean()\n",
    "            Precision_train = scores['test_prec_micro'].mean()\n",
    "            Recall_train = scores['test_rec_micro'].mean()\n",
    "            F1_train = scores['test_f1_micro'].mean()\n",
    "            AUC_train = scores['test_auc'].mean()\n",
    "            conf_matrix_train = confusion_matrix(y_train, ypredTrain)\n",
    "            class_report = classification_report(y_train, ypredTrain)\n",
    "            print(\"TRAIN:\\n===========================================\")\n",
    "            print(f\"CV - Accuracy : {Acc_train:.2f}\\n\")\n",
    "            print(f\"CV - Precision: {Precision_train:.2f}\\n\")\n",
    "            print(f\"CV - Recall: {Recall_train:.2f}\\n\")\n",
    "            print(f\"CV - F1 score: {F1_train:.2f}\\n\")   \n",
    "            print(f\"CV - AUC score: {AUC_train:.2f}\\n\")  \n",
    "            print(f\"Confusion Matrix:\\n {conf_matrix_train}\\n\")\n",
    "            print(f\"Classification Report:\\n {class_report}\\n\")\n",
    "    elif train==False:\n",
    "        if cv==True:\n",
    "            kfold=StratifiedKFold(n_splits=10, random_state=42)\n",
    "            scores = cross_validate(model, X_test, y_test, scoring=scoring, cv=kfold)\n",
    "            ypredTest = model.predict(X_test)\n",
    "            Acc_test = scores['test_acc'].mean()\n",
    "            Precision_test = scores['test_prec_micro'].mean()\n",
    "            Recall_test = scores['test_rec_micro'].mean()\n",
    "            F1_test = scores['test_f1_micro'].mean()\n",
    "            AUC_test = scores['test_auc'].mean()\n",
    "            conf_matrix_test = confusion_matrix(y_test, ypredTest)\n",
    "            class_report = classification_report(y_test, ypredTest)        \n",
    "            print(\"TEST:\\n===========================================\")\n",
    "            print(f\"CV - Accuracy : {Acc_test:.2f}\\n\")\n",
    "            print(f\"CV - Precision: {Precision_test:.2f}\\n\")\n",
    "            print(f\"CV - Recall: {Recall_test:.2f}\\n\")\n",
    "            print(f\"CV - F1 score: {F1_test:.2f}\\n\")    \n",
    "            print(f\"CV - AUC score: {AUC_test:.2f}\\n\")   \n",
    "            print(f\"Confusion Matrix:\\n {conf_matrix_test}\\n\")\n",
    "            print(f\"Classification Report:\\n {class_report}\\n\")\n",
    "        elif cv==False:\n",
    "            scores = cross_validate(model, X_test, y_test, scoring=scoring)\n",
    "            ypredTest = model.predict(X_test)\n",
    "            Acc_test = scores['test_acc'].mean()\n",
    "            Precision_test = scores['test_prec_micro'].mean()\n",
    "            Recall_test = scores['test_rec_micro'].mean()\n",
    "            F1_test = scores['test_f1_micro'].mean()\n",
    "            AUC_test = scores['test_auc'].mean()\n",
    "            conf_matrix_test = confusion_matrix(y_test, ypredTest)\n",
    "            class_report = classification_report(y_test, ypredTest)        \n",
    "            print(\"TEST:\\n===========================================\")\n",
    "            print(f\"CV - Accuracy : {Acc_test:.2f}\\n\")\n",
    "            print(f\"CV - Precision: {Precision_test:.2f}\\n\")\n",
    "            print(f\"CV - Recall: {Recall_test:.2f}\\n\")\n",
    "            print(f\"CV - F1 score: {F1_test:.2f}\\n\")    \n",
    "            print(f\"CV - AUC score: {AUC_test:.2f}\\n\")   \n",
    "            print(f\"Confusion Matrix:\\n {conf_matrix_test}\\n\")\n",
    "            print(f\"Classification Report:\\n {class_report}\\n\")   \n",
    "# OV train\n",
    "print('Oversampled Model\\n')\n",
    "print(performance_metrics(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=True, cv=True))\n",
    "# OV test\n",
    "print('Oversampled Model\\n')\n",
    "print(performance_metrics(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=False, cv=False))\n",
    "# OR train\n",
    "print('Original Model\\n')\n",
    "print(performance_metrics(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=True, cv=False))\n",
    "# OR test\n",
    "print('Original Model\\n')\n",
    "print(performance_metrics(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=False, cv=False))\n",
    "# Projected (PJ; i.e. oversampled test)\n",
    "print('Projected Model\\n')\n",
    "print(performance_metrics(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_testres, ysel_testres, train=False, cv=True))\n",
    "\n",
    "# Performance figures\n",
    "def pr_curve(model, X_train, y_train, X_test, y_test, train=True):\n",
    "    \"\"\"\n",
    "    Plots a precision/recall curve of a given classification model\n",
    "    train = True to evaluate train subset, = False test subset\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    if train==True:\n",
    "        ypredTrain = model.predict(X_train)   \n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_train, ypredTrain)\n",
    "        plt.plot(precisions, recalls, linewidth=3, color='r', linestyle='-')\n",
    "        plt.rc('xtick', labelsize=10)    \n",
    "        plt.rc('ytick', labelsize=10)  \n",
    "        plt.xlabel(\"Precision\", size=12)\n",
    "        plt.ylabel(\"Recall\", size=12)\n",
    "        plt.grid()\n",
    "        plt.rcParams['figure.facecolor'] = '#F2F3F4'            \n",
    "        plt.rcParams['axes.facecolor'] = '#F2F3F4'                           \n",
    "        plt.title(\"PR Curve: Precision/Recall Trade-off\\n\\n(Train)\\n\", size=14)          \n",
    "        plt.show()\n",
    "    elif train==False:\n",
    "        ypredTest = model.predict(X_test)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, ypredTest)\n",
    "        plt.plot(precisions, recalls, linewidth=3, color='b', linestyle='-')\n",
    "        plt.rc('xtick', labelsize=10)    \n",
    "        plt.rc('ytick', labelsize=10)  \n",
    "        plt.xlabel(\"Precision\", size=12)\n",
    "        plt.ylabel(\"Recall\", size=12)\n",
    "        plt.grid()\n",
    "        plt.rcParams['figure.facecolor'] = '#F2F3F4'            \n",
    "        plt.rcParams['axes.facecolor'] = '#F2F3F4'\n",
    "        plt.title(\"PR Curve: Precision/Recall Trade-off\\n\\n(Test)\\n\", size=14)\n",
    "        plt.show()\n",
    "pr_curve(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=True) # OV train\n",
    "pr_curve(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=False) # OV test\n",
    "pr_curve(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=True) # OR train\n",
    "pr_curve(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=False) # OR test\n",
    "pr_curve(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_testres, ysel_testres, train=False) # PJ test\n",
    "def roc_curve(model, X_train, y_train, X_test, y_test, train=True):  \n",
    "    \"\"\"\n",
    "    Plots a ROC curve of a given classification model\n",
    "    train = True to evaluate train subset, = False test subset\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve\n",
    "    if train==True:\n",
    "        ypredTrain = model.predict(X_train)\n",
    "        fpr, tpr, thresholds = roc_curve(y_train, ypredTrain)\n",
    "        plt.plot(fpr, tpr, linewidth=3, label=None, color='r', linestyle='-')\n",
    "        plt.rc('xtick', labelsize=10)    \n",
    "        plt.rc('ytick', labelsize=10)  \n",
    "        plt.xlabel('False Positive Rate', size=12)\n",
    "        plt.ylabel('True Positive Rate', size=12)\n",
    "        plt.grid()\n",
    "        plt.rcParams['figure.facecolor'] = '#F2F3F4'            \n",
    "        plt.rcParams['axes.facecolor'] = '#F2F3F4'  \n",
    "        plt.title(\"ROC Curve: Sensitivity/Specificity Trade-off\\n\\n(Train)\\n\", size=14)\n",
    "        plt.show()\n",
    "    elif train==False:\n",
    "        ypredTest = model.predict(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, ypredTest)\n",
    "        plt.plot(fpr, tpr, linewidth=3, label=None, color='b', linestyle='-')\n",
    "        plt.rc('xtick', labelsize=10)    \n",
    "        plt.rc('ytick', labelsize=10)  \n",
    "        plt.xlabel('False Positive Rate', size=12)\n",
    "        plt.ylabel('True Positive Rate', size=12)\n",
    "        plt.grid()\n",
    "        plt.rcParams['figure.facecolor'] = '#F2F3F4'            \n",
    "        plt.rcParams['axes.facecolor'] = '#F2F3F4'\n",
    "        plt.title('ROC Curve: Sensitivity/Specificity Trade-off\\n\\n(Test)\\n', size=14)\n",
    "        plt.show()\n",
    "roc_curve(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=True) # OV train\n",
    "roc_curve(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=False) # OV test\n",
    "roc_curve(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=True) # OR train\n",
    "roc_curve(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=False) # OR test\n",
    "roc_curve(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_testres, ysel_testres, train=False) # PJ test\n",
    "def conf_matrix(model, X_train, y_train, X_test, y_test, train=True): \n",
    "    \"\"\"\n",
    "    Plots a confusion matrix of a given classification model\n",
    "    train = True to evaluate train subset, = False test subset\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import itertools\n",
    "    if train==True:    \n",
    "        ypredTrain = model.predict(X_train)\n",
    "        cm = confusion_matrix(y_train, ypredTrain)\n",
    "        def plot_conf_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Reds):\n",
    "            plt.figure(figsize = (5, 5))\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "            plt.title(title, size = 14)\n",
    "            plt.colorbar(aspect=4)\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            plt.xticks(tick_marks, classes, rotation=0, size = 10)\n",
    "            plt.yticks(tick_marks, classes, size = 10)\n",
    "            fmt = 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                plt.text(j, i, format(cm[i, j], fmt), fontsize = 14,\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "                plt.grid(b=None)\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label', size = 12)\n",
    "            plt.xlabel('Predicted label', size = 12)\n",
    "        plot_conf_matrix(cm, classes = ['Covid-', 'Covid+'], \n",
    "                                  title = 'Confusion Matrix\\n\\n(Train)\\n')\n",
    "    elif train==False:\n",
    "        ypredTest = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, ypredTest)\n",
    "        def plot_conf_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "            plt.figure(figsize = (5, 5))\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "            plt.title(title, size = 14)\n",
    "            plt.colorbar(aspect=4)\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            plt.xticks(tick_marks, classes, rotation=0, size = 10)\n",
    "            plt.yticks(tick_marks, classes, size = 10)\n",
    "            fmt = 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                plt.text(j, i, format(cm[i, j], fmt), fontsize = 14,\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "                plt.grid(b=None)\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label', size = 12)\n",
    "            plt.xlabel('Predicted label', size = 12)\n",
    "        plot_conf_matrix(cm, classes = ['Covid-', 'Covid+'], \n",
    "                                  title = 'Confusion Matrix\\n\\n(Test)\\n')        \n",
    "conf_matrix(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=True) # OV train          \n",
    "conf_matrix(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_test, ysel_test, train=False) # OV test\n",
    "conf_matrix(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=True) # OR train\n",
    "conf_matrix(dtmodel_or, Xsel_train, yselrf_train, Xsel_test, ysel_test, train=False) # OR test\n",
    "conf_matrix(dtmodel_ov, Xsel_trainres, yselrf_trainres, Xsel_testres, ysel_testres, train=False) # PJ test\n",
    "\n",
    "# Predictions on test\n",
    "dtmodel_ov_classPred = dtmodel_ov.predict(Xsel_test) # OV model\n",
    "print('Classification predictions: \\n', dtmodel_ov_classPred)\n",
    "dtmodel_ov_probPred = dtmodel_ov.predict_proba(Xsel_test)[:, 1]\n",
    "print('Predictions probabilities: \\n', dtmodel_ov_probPred)\n",
    "dtmodel_or_classPred = dtmodel_or.predict(Xsel_test) # OR model\n",
    "print('Classification predictions: \\n', dtmodel_or_classPred)\n",
    "dtmodel_or_probPred = dtmodel_or.predict_proba(Xsel_test)[:, 1]\n",
    "print('Predictions probabilities: \\n', dtmodel_or_probPred)\n",
    "dtmodel_ov_classPred = dtmodel_ov.predict(Xsel_testres) # PJ model\n",
    "print('Classification predictions: \\n', dtmodel_ov_classPred)\n",
    "dtmodel_ov_probPred = dtmodel_ov.predict_proba(Xsel_testres)[:, 1]\n",
    "print('Predictions probabilities: \\n', dtmodel_ov_probPred)\n",
    "\n",
    "\n",
    "### MODEL INTERPRETATION\n",
    "\n",
    "# Decision Tree figures\n",
    "featurenames = ['gender', 'preconditions', 'immunosupressed', 'pidsid', # define features names\n",
    "       'admpicu', 'respiratory', 'gastrointestinal', 'fever', 'cxr',\n",
    "       'pneumonia', 'oxigen', 'antibiotics', 'corticoids', 'age',\n",
    "       'neutrocytes', 'lymphocytes', 'crp',\n",
    "       'diagnosisdelay']\n",
    "classnames = ['CovidNeg','CovidPos'] # define class names\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "# OV standardised\n",
    "dot_data = tree.export_graphviz(dtmodel_ov, \n",
    "                                out_file=None,  \n",
    "                                feature_names=featurenames,\n",
    "                                class_names=classnames, \n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render('dtree_ov',view=True) # creates and opens pdf file in working folder\n",
    "# OV non-standardised\n",
    "dot_data = tree.export_graphviz(dtmodelns_ov, \n",
    "                                out_file=None,  \n",
    "                                feature_names=featurenames,\n",
    "                                class_names=classnames, \n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render('dtree_ovns',view=True)\n",
    "# OR standardised\n",
    "dot_data = tree.export_graphviz(dtmodel_or, \n",
    "                                out_file=None,  \n",
    "                                feature_names=featurenames,\n",
    "                                class_names=classnames, \n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render('dtree_or',view=True)\n",
    "# OR non-standardised\n",
    "dot_data = tree.export_graphviz(dtmodelns_or, \n",
    "                                out_file=None,  \n",
    "                                feature_names=featurenames,\n",
    "                                class_names=classnames, \n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render('dtree_orns',view=True)\n",
    "\n",
    "# Feature importance analyses & figures (SHAP method)\n",
    "#conda install -c conda-forge (if cannot be installed through Anaconda console)\n",
    "import shap\n",
    "# OV standardised - Feature Importance Plot: Global Interpretability\n",
    "shap_values_dtov = shap.TreeExplainer(dtmodel_ov).shap_values(Xsel_trainres)\n",
    "shap.summary_plot(shap_values_dtov, Xsel_trainres, plot_type=\"bar\")\n",
    "# OV standardised - Individual SHAP Value Plot ‚Äî Local Interpretability \n",
    "X_output_dtov = Xsel_test.copy()\n",
    "X_output_dtov.loc[:,'predict'] = np.round(dtmodel_ov.predict(X_output_dtov),2)\n",
    "explainer_dtov = shap.TreeExplainer(dtmodel_ov)\n",
    "choosen_instance_dtov0 = X_output_dtov.loc[[0]] # positive case example\n",
    "shap_values_dtov0 = explainer_dtov.shap_values(choosen_instance_dtov0)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtov.expected_value[1], shap_values_dtov0[1], choosen_instance_dtov0, \n",
    "                show=True, matplotlib=True)\n",
    "choosen_instance_dtov10 = X_output_dtov.loc[[10]] # negative case example\n",
    "shap_values_dtov10 = explainer_dtov.shap_values(choosen_instance_dtov10)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtov.expected_value[1], shap_values_dtov10[1], choosen_instance_dtov10, \n",
    "                show=True, matplotlib=True, figsize=[27,2.5]) \n",
    "# OV non-standardised - Feature Importance Plot: Global Interpretability\n",
    "shap_values_dtovns = shap.TreeExplainer(dtmodelns_ov).shap_values(Xselns_trainres)\n",
    "shap.summary_plot(shap_values_dtovns, Xselns_trainres, plot_type=\"bar\")\n",
    "# OV non- standardised - Individual SHAP Value Plot ‚Äî Local Interpretability \n",
    "X_output_dtovns = Xselns_test.copy()\n",
    "X_output_dtovns.loc[:,'predict'] = np.round(dtmodelns_ov.predict(X_output_dtovns),2)\n",
    "explainer_dtovns = shap.TreeExplainer(dtmodelns_ov)\n",
    "choosen_instance_dtovns0 = X_output_dtovns.loc[[0]] # positive case example\n",
    "shap_values_dtovns0 = explainer_dtovns.shap_values(choosen_instance_dtovns0)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtovns.expected_value[1], shap_values_dtovns0[1], choosen_instance_dtovns0, \n",
    "                show=True, matplotlib=True) \n",
    "choosen_instance_dtovns11 = X_output_dtovns.loc[[11]] # negative case example\n",
    "shap_values_dtovns11 = explainer_dtovns.shap_values(choosen_instance_dtovns11)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtovns.expected_value[1], shap_values_dtovns11[1], choosen_instance_dtovns11, \n",
    "                show=True, matplotlib=True)#, figsize=[27,2.5]) \n",
    "# OR standardised - Feature Importance Plot: Global Interpretability\n",
    "shap_values_dtor = shap.TreeExplainer(dtmodel_or).shap_values(Xsel_train)\n",
    "shap.summary_plot(shap_values_dtor, Xsel_train, plot_type=\"bar\")\n",
    "# OR standardised - Individual SHAP Value Plot ‚Äî Local Interpretability \n",
    "X_output_dtor = Xsel_test.copy()\n",
    "X_output_dtor.loc[:,'predict'] = np.round(dtmodel_or.predict(X_output_dtor),2)\n",
    "explainer_dtor = shap.TreeExplainer(dtmodel_or)\n",
    "choosen_instance_dtor28 = X_output_dtor.loc[[28]] # positive case example\n",
    "shap_values_dtor28 = explainer_dtor.shap_values(choosen_instance_dtor28)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtor.expected_value[1], shap_values_dtor28[1], choosen_instance_dtor28, \n",
    "                show=True, matplotlib=True, figsize=[27,2.5]) \n",
    "choosen_instance_dtor10 = X_output_dtor.loc[[10]] # negative case example\n",
    "shap_values_dtor10 = explainer_dtor.shap_values(choosen_instance_dtor10)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtor.expected_value[1], shap_values_dtor10[1], choosen_instance_dtor10, \n",
    "                show=True, matplotlib=True, figsize=[24,2.5])\n",
    "# OR non-standardised - Feature Importance Plot: Global Interpretability\n",
    "shap_values_dtorns = shap.TreeExplainer(dtmodelns_or).shap_values(Xselns_train)\n",
    "shap.summary_plot(shap_values_dtorns, Xselns_train, plot_type=\"bar\")\n",
    "# OR non- standardised - Individual SHAP Value Plot ‚Äî Local Interpretability \n",
    "X_output_dtorns = Xselns_test.copy()\n",
    "X_output_dtorns.loc[:,'predict'] = np.round(dtmodelns_or.predict(X_output_dtorns),2)\n",
    "explainer_dtorns = shap.TreeExplainer(dtmodelns_or)\n",
    "choosen_instance_dtorns15 = X_output_dtorns.loc[[15]] # positive case example\n",
    "shap_values_dtorns15 = explainer_dtorns.shap_values(choosen_instance_dtorns15)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtorns.expected_value[1], shap_values_dtorns15[1], choosen_instance_dtorns15, \n",
    "                show=True, matplotlib=True) \n",
    "choosen_instance_dtorns10 = X_output_dtorns.loc[[10]] # negative case example\n",
    "shap_values_dtorns10 = explainer_dtorns.shap_values(choosen_instance_dtorns10)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_dtorns.expected_value[1], shap_values_dtorns10[1], choosen_instance_dtorns10, \n",
    "                show=True, matplotlib=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
